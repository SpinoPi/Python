{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is to repeat the partial least squares regression process in a paper[1].  \n",
    "[1] Partial least squares regression and projection on latent structure regression (PLS Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PLSCJ():\n",
    "    \n",
    "    def __init__(self, n_components = None):\n",
    "        \n",
    "        self.PC = n_components\n",
    "    \n",
    "    def fit(self, X, Y, scale = True,ddof=1):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        E, F, self.x_mean, self.y_mean, self.x_std, self.y_std = self._center_scale(X, Y, scale,ddof)\n",
    "        \n",
    "        T, U, W, B, P, C = self._pls(E, F)      \n",
    "        \n",
    "        #X = TP'\n",
    "        #Y = UQ'\n",
    "        \n",
    "        #Be aware that T, W, C is orthogonal; P, U, Q is not orthogonal.\n",
    "        #Ybar is the estimated Y.\n",
    "        #Ybar = TBC' Be noticed that this B is tranformed into diagonal matrix\n",
    "        #Ybar = TQ'\n",
    "        #In this calculation method, the loadings of y is not actually appeared.\n",
    "        \n",
    "        Q = np.dot(np.diag(B),C.T).T #Q = (BC')'\n",
    "                \n",
    "        self.x_scores_ = T\n",
    "        self.y_scores_ = U\n",
    "        self.x_weights_ = W\n",
    "        self.y_weights_ = C\n",
    "        self.x_loadings_ = P\n",
    "        self.y_loadings_ = Q\n",
    "        self.regression_weights_ = B\n",
    "        \n",
    "        \n",
    "        #Ybar = TBC' = XBpls with Bpls = (P'+)BC' \n",
    "        #where P'+ is the Moore–Penrose pseudo-inverse of P'\n",
    "        \n",
    "        Bpls = np.dot(np.dot(sp.linalg.pinv2(P.T),np.diag(B)),C.T)\n",
    "        self.Bpls_ = Bpls\n",
    "        Bpls = (Bpls.T/self.x_std).T # np.dot(A/B,C) = np.dot(A,(C.T/B).T)\n",
    "        self.coef_ = Bpls*self.y_std\n",
    "        self.intercept = -(np.dot(self.x_mean,Bpls))*self.y_std+self.y_mean\n",
    "        \n",
    "    def _center_scale(self, X, Y, scale=True,ddof=1):\n",
    "\n",
    "    # center\n",
    "        E = X.copy()\n",
    "        F = Y.copy()\n",
    "        x_mean = X.mean(axis=0)\n",
    "        x_std = X.std(axis=0, ddof=ddof)\n",
    "        E -= x_mean\n",
    "        y_mean = Y.mean(axis=0)\n",
    "        y_std = Y.std(axis=0, ddof=ddof)\n",
    "        F -= y_mean\n",
    "    # scale\n",
    "        if scale:\n",
    "            E /= x_std\n",
    "            F /= y_std\n",
    "        else:\n",
    "            x_std = np.ones(X.shape[1])\n",
    "            y_std = np.ones(Y.shape[1])\n",
    "        \n",
    "        return E, F, x_mean, y_mean, x_std, y_std    \n",
    "            \n",
    "    def _niplas(self, E, F, u):\n",
    "        \n",
    "        #Note: the symbol ∝ means ‘to normalize the result of the operation’\n",
    "        #Step 1. w ∝ E'u (estimate X weights).\n",
    "        #Step 2. t ∝ Ew (estimate X factor scores).\n",
    "        #Step 3. c ∝ F't (estimate Y weights). \n",
    "        #Step 4. u = Fc (estimate Y scores). Be aware that Y scores is not orthogonal.\n",
    "        #b = t'u\n",
    "        #p = E't\n",
    "        #E = E − tp'\n",
    "        #F = F − btc'\n",
    "        \n",
    "        #Blow is the original method to estimate the first vector\n",
    "   \n",
    "        w = np.dot(E.T,u)\n",
    "        w = w/np.linalg.norm(w) #not equal to w/np.dot(u.T,u)\n",
    "        t = np.dot(E,w)\n",
    "        t = t/np.linalg.norm(t) #not equal to t/np.dot(w.T,w)\n",
    "        c = np.dot(F.T,t)\n",
    "        c = c/np.linalg.norm(c) #not equal to q/np.dot(t.T,t)\n",
    "        u = np.dot(F,c)\n",
    "        to = t\n",
    "        conv = 1\n",
    "        while conv > 10**-8:\n",
    "            w = np.dot(E.T,u)\n",
    "            w = w/np.linalg.norm(w)\n",
    "            t = np.dot(E,w)\n",
    "            t = t/np.linalg.norm(t)\n",
    "            c = np.dot(F.T,t)\n",
    "            c = c/np.linalg.norm(c) # is different with c/np.dot(t.T,t)\n",
    "            u = np.dot(F,c)\n",
    "            conv = abs(np.linalg.norm(to-t))/abs(np.linalg.norm(t))\n",
    "            to = t\n",
    "        b = np.dot(t.T,u)\n",
    "        p = np.dot(E.T,t)\n",
    "        E = E - np.dot(t,p.T)\n",
    "        F = F - b*np.dot(t,c.T)\n",
    "        \n",
    "        #In sklearn's PLS regression, the F is not calculated by the regression weights b.\n",
    "        #The b is equal to I for each steps here.\n",
    "        #So the Fbar is estimated by TQ'. Where Q is calculated by Q = Yk'U.\n",
    "        #Because the Ybar = TBC' = TQ', the C is equal to Q in the sklearn's PLS regression finally.\n",
    "        \n",
    "        return t, u, w, b, p, c, E, F\n",
    "        \n",
    "    def _pls(self, E, F):\n",
    "    \n",
    "        T = None \n",
    "        U = None\n",
    "        P = None\n",
    "        W = None\n",
    "        B = None\n",
    "        c = None\n",
    "        \n",
    "        PC_iter = 0\n",
    "        observation,factor = E.shape \n",
    "\n",
    "        #u = F[:,0]\n",
    "        #The first column of Y could be used as the first Y scores.\n",
    "        #Because w ∝ E'u ∝ E'Fc ∝ E'FF't ∝ E'FF'Ew, \n",
    "        #the weight vector w is the first right singular vector of the matrix,\n",
    "        #the first weight vector c is the left singular vector of S.\n",
    "        #Below I use this method to speed up the convergence.\n",
    "        \n",
    "        \n",
    "        S = np.dot(E.T,F)\n",
    "        w,D,c = sp.linalg.svd(S)\n",
    "        c = c.T\n",
    "        w = w[:,0]\n",
    "        c = c[:,0]       \n",
    "        u = np.dot(F,c)\n",
    "        u.shape = (observation,1)\n",
    "        \n",
    "        if type(self.PC) is int:\n",
    "            \n",
    "            if self.PC > factor or self.PC < 1:\n",
    "                    raise ValueError('Invalid number of components: %d' %\n",
    "                                     self.PC)\n",
    "            else:\n",
    "                \n",
    "                factor = self.PC\n",
    "                \n",
    "                while PC_iter < factor:\n",
    "                \n",
    "                    if PC_iter is 0:\n",
    "                    \n",
    "                        T, U, W, B, P, C, E, F = self._niplas(E, F, u)\n",
    "                \n",
    "                    else:\n",
    "                    \n",
    "                        t, u, w, b, p, c, E, F = self._niplas(E, F, u)\n",
    "                        T = np.column_stack((T,t))\n",
    "                        U = np.column_stack((U,u))\n",
    "                        W = np.column_stack((W,w))\n",
    "                        P = np.column_stack((P,p))\n",
    "                        B = np.column_stack((B,b))\n",
    "                        C = np.column_stack((C,c))\n",
    "                \n",
    "                    PC_iter = len(T.T)    \n",
    "        \n",
    "        elif self.PC is None:\n",
    "            \n",
    "            while (np.linalg.norm(E)>(10**-15)) and (PC_iter <= factor):\n",
    "                                \n",
    "                if PC_iter is 0:\n",
    "                    \n",
    "                    T, U, W, B, P, C, E, F = self._niplas(E, F, u)\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    t, u, w, b, p, c, E, F = self._niplas(E, F, u)\n",
    "                    T = np.column_stack((T,t))\n",
    "                    U = np.column_stack((U,u))\n",
    "                    W = np.column_stack((W,w))\n",
    "                    B = np.column_stack((B,b))\n",
    "                    P = np.column_stack((P,p))\n",
    "                    C = np.column_stack((C,c))\n",
    "                \n",
    "                PC_iter = len(T.T)\n",
    "                          \n",
    "        else:\n",
    "            \n",
    "            raise ValueError('Invalid number of components: %d' %\n",
    "                             self.PC)\n",
    "        \n",
    "        #Because the shape of B is 2-dimensional like (1,3), but we need it reshaped as 1-dimensional like (3,)\n",
    "        #to be conveniently used, such as, to be diagonalized by numpy.diag().\n",
    "         \n",
    "        return T, U, W, B[0,:], P, C\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        return np.dot(X,self.coef_)+self.intercept\n",
    "    \n",
    "    def parameter(self):\n",
    "        \n",
    "        #Export parameters for testing.\n",
    "        \n",
    "        return self.x_scores_, self.y_scores_, self.x_weights_, self.y_weights_, self.x_loadings_, self.y_loadings_, self.regression_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sWine = pd.Series(['1','2','3','4','5'],)\n",
    "data_Y = {'Hedonic':[14,10,8,2,6],\n",
    "          'Goes with Meat':[7,7,5,4,2],\n",
    "          'Goes with Dessert':[8,6,5,7,4]}\n",
    "dY = pd.DataFrame(data_Y,columns=['Hedonic','Goes with Meat','Goes with Dessert'],index=sWine)\n",
    "naY = np.array(dY,dtype='float64')\n",
    "\n",
    "data_X = {'Price':[7,4,10,16,13],\n",
    "          'Sugar':[7,3,5,7,3],\n",
    "          'Alchol':[13,14,12,11,10],\n",
    "          'Acidity':[7,7,5,3,3]}\n",
    "dX = pd.DataFrame(data_X,columns=['Price','Sugar','Alchol','Acidity'],index=sWine)\n",
    "naX = np.array(dX,dtype='float64')\n",
    "\n",
    "data_T = {'t1':[0.4538,0.5399,0,-0.4304,-0.5633],\n",
    "          't2':[-0.4662,0.4940,0,-0.5327,0.5049],\n",
    "          't3':[0.5716,-0.4631,0,-0.5301,0.4217]}\n",
    "dT = pd.DataFrame(data_T,columns=['t1','t2','t3'],index=sWine)\n",
    "naT = np.array(dT)\n",
    "\n",
    "data_U = {'u1':[1.9451,0.9347,-0.2327,-0.9158,-1.7313],\n",
    "          'u2':[-0.7611,0.5305,0.6084,-1.1575,0.7797],\n",
    "          'u3':[0.6191,-0.5388,0.0823,-0.6139,0.4513]}\n",
    "dU = pd.DataFrame(data_U,columns=['u1','u2','u3'],index=sWine)\n",
    "naU = np.array(dU)\n",
    "\n",
    "data_P = {'p1':[-1.8706,0.0468,1.9547,1.9874],\n",
    "          'p2':[-0.6845,-1.9977,0.0283,0.0556],\n",
    "          'p3':[-0.1796,0.0829,-0.4224,0.2170]}\n",
    "dP = pd.DataFrame(data_P,columns=['p1','p2','p3'],index=['Price','Sugar','Alchol','Acidity'])\n",
    "naP = np.array(dP)\n",
    "\n",
    "data_W = {'w1':[-0.5137,0.2010,0.5705,0.6085],\n",
    "          'w2':[-0.3379,-0.9400,-0.0188,0.0429],\n",
    "          'w3':[-0.3492,0.1612,-0.8211,0.4218]}\n",
    "dW = pd.DataFrame(data_W,columns=['w1','w2','w3'],index=['Price','Sugar','Alchol','Acidity'])\n",
    "naW = np.array(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = naX\n",
    "Y_true = naY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for 1 component: 0.633\n",
      "R2 for 2 component: 0.221\n",
      "R2 for 3 component: 0.104\n",
      "R2 for all components: 0.958\n",
      "R2 for all components: 0.958\n"
     ]
    }
   ],
   "source": [
    "plscj = PLSCJ(n_components=3)\n",
    "plscj.fit(X,Y_true)\n",
    "r2_sum = 0\n",
    "for i in range(0,3):\n",
    "    Y_pred=np.dot(plscj.x_scores_[:,i].reshape(-1,1)*plscj.regression_weights_[i],plscj.y_weights_[:,i].reshape(-1,1).T)*naY.std(axis=0, ddof=1)+naY.mean(axis=0)\n",
    "    r2_sum += round(r2_score(Y_true,Y_pred),3) \n",
    "    print('R2 for %d component: %g' %(i+1,round(r2_score(Y_true,Y_pred),3)))\n",
    "print('R2 for all components: %g' %r2_sum) #Sum of above\n",
    "print('R2 for all components: %g' %round(r2_score(Y_true,plscj.predict(X)),3)) #Calcuted from PLSRegres's 'predict' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for 1 component: 0.633\n",
      "R2 for 2 component: 0.221\n",
      "R2 for 3 component: 0.104\n",
      "R2 for all components: 0.958\n",
      "R2 for all components: 0.958\n"
     ]
    }
   ],
   "source": [
    "pls = PLSRegression(n_components=3)\n",
    "pls.fit(X,Y_true)\n",
    "r2_sum = 0\n",
    "for i in range(0,3):\n",
    "    Y_pred=np.dot(pls.x_scores_[:,i].reshape(-1,1),pls.y_loadings_[:,i].reshape(-1,1).T)*naY.std(axis=0, ddof=1)+naY.mean(axis=0)\n",
    "    r2_sum += round(r2_score(Y_true,Y_pred),3) \n",
    "    print('R2 for %d component: %g' %(i+1,round(r2_score(Y_true,Y_pred),3)))\n",
    "print('R2 for all components: %g' %r2_sum) #Sum of above\n",
    "print('R2 for all components: %g' %round(r2_score(Y_true,pls.predict(X)),3)) #Calcuted from PLSRegression's 'predict' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "   Price  Sugar  Alchol  Acidity\n",
      "1      7      7      13        7\n",
      "2      4      3      14        7\n",
      "3     10      5      12        5\n",
      "4     16      7      11        3\n",
      "5     13      3      10        3\n",
      "Actual Y:\n",
      "   Hedonic  Goes with Meat  Goes with Dessert\n",
      "1       14               7                  8\n",
      "2       10               7                  6\n",
      "3        8               5                  5\n",
      "4        2               4                  7\n",
      "5        6               2                  4\n",
      "Estimated Y from sklearn PLSRegression:\n",
      "   Hedonic  Goes with Meat  Goes with Dessert\n",
      "1     14.0             7.0               7.75\n",
      "2     10.0             7.0               5.75\n",
      "3      8.0             5.0               6.00\n",
      "4      2.0             4.0               6.75\n",
      "5      6.0             2.0               3.75\n",
      "Estimated Y from PLSCJ:\n",
      "   Hedonic  Goes with Meat  Goes with Dessert\n",
      "1     14.0             7.0               7.75\n",
      "2     10.0             7.0               5.75\n",
      "3      8.0             5.0               6.00\n",
      "4      2.0             4.0               6.75\n",
      "5      6.0             2.0               3.75\n"
     ]
    }
   ],
   "source": [
    "print('X:')\n",
    "print(dX)\n",
    "print('Actual Y:')\n",
    "print(dY)\n",
    "print('Estimated Y from sklearn PLSRegression:')\n",
    "print(pd.DataFrame(pls.predict(X),columns=['Hedonic','Goes with Meat','Goes with Dessert'],index=sWine))\n",
    "print('Estimated Y from PLSCJ:')\n",
    "print(pd.DataFrame(plscj.predict(X),columns=['Hedonic','Goes with Meat','Goes with Dessert'],index=sWine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T,U,W,C,P,Q,B = plscj.parameter()\n",
    "E = (X-X.mean(axis=0))/X.std(axis=0,ddof=1)\n",
    "F = (Y_true-Y_true.mean(axis=0))/Y_true.std(axis=0,ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
